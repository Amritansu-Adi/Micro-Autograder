# Micro Autograder

**Micro Autograder** is a minimal Python implementation of a simple autograd engine. It allows you to build and train basic models by mimicking the core principles of frameworks like PyTorchâ€”especially the automatic differentiation (autograd) mechanism.

## ðŸš€ Features

- Pure Python (no external ML libraries required)
- Custom `Tensor` class for tracking data and gradients
- Forward and backward propagation for basic operations
- Implemented operations:
  - `add`
  - `multiply`
  - `divide`
  - `tanh`
  - `power` (optional)
  - More to come!

## ðŸ§  Motivation

The goal is to understand how autograd systems like PyTorch work under the hood by implementing a mini version from scratch. It is educational and useful for beginners who want to explore deep learning internals.

